{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Variational Optimization: PYTHIA Tuning\n",
    "\n",
    "In this notebook Adversarial Variational Optimization (https://arxiv.org/abs/1707.07113) is applied to tuning parameters of a simplistic detector.\n",
    "\n",
    "**Note: this notebook takes quite a long time to execute. It is recommended to run all cells at the beginning.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please, don't interrupt the notebook while sampling from PythiaMill. Otherwise it might stuck at the next attempt to sample from it. IF this happens, please, restart the notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm_notebook\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed to create session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fc39a27297a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgpu_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPUOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_process_gpu_memory_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtf_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/mlhep2018/pyenv/versions/3.6.6/envs/mlhep/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1709\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_pruned_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1711\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1712\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mInteractiveSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mInteractiveSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_session_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/mlhep2018/pyenv/versions/3.6.6/envs/mlhep/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to create session."
     ]
    }
   ],
   "source": [
    "### don't forget about others!\n",
    "\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.2)\n",
    "tf_session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "keras.backend.tensorflow_backend.set_session(tf_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators\n",
    "\n",
    "Pythia-mill is a python binding to Pythia generator that can run in multiple threads (processes).\n",
    "For more details, please, visit https://github.com/maxim-borisyak/pythia-mill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pythiamill as pm\n",
    "\n",
    "SEED=123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note about the change of problem\n",
    "\n",
    "The reason the detector parameters (instead of Pythia parameters) are the target for the tune is a purely technical one: on each step AVO requires samples from multiples configurations of generator + detector. However, Pythia requires about half of a second to be reconfigured, which induces a tremendous overhead.\n",
    "\n",
    "By contrast, this simplistic detector is designed to accept its parameters as function arguments (effectively neglecting any overhead).\n",
    "\n",
    "\n",
    "The detector emulates a $32 \\times 32$ spherical uniform grid in `pseudorapidity` ($\\eta$)-`angle in traverse plane` ($\\phi$) covering $(\\eta, \\phi) \\in [0, 5] \\times [0, 2 \\pi]$.\n",
    "\n",
    "The detector is parametrized by offset in $z$-axis relative to the beam crossing point. Zero offset means that center of the sphere coincides with the collision point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ground truth offset, unknown in the real world problems.\n",
    "TRUE_OFFSET=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [\n",
    "    ### telling pythia to be quiet.\n",
    "    'Print:quiet = on',\n",
    "    'Init:showProcesses = off',\n",
    "    'Init:showMultipartonInteractions = off',\n",
    "    'Init:showChangedSettings = off',\n",
    "    'Init:showChangedParticleData = off',\n",
    "    'Next:numberCount=0',\n",
    "    'Next:numberShowInfo=0',\n",
    "    'Next:numberShowEvent=0',\n",
    "    'Stat:showProcessLevel=off',\n",
    "    'Stat:showErrors=off',\n",
    "    \n",
    "    ### seeting default parameters to Monash values\n",
    "    ### all options are taken from https://arxiv.org/abs/1610.08328\n",
    "    \"Tune:ee = 7\",\n",
    "    \"Beams:idA = 11\",\n",
    "    \"Beams:idB = -11\",\n",
    "    \"Beams:eCM = 91.2\",\n",
    "    \"WeakSingleBoson:ffbar2gmZ = on\",\n",
    "    \"23:onMode = off\",\n",
    "    \"23:onIfMatch = 1 -1\",\n",
    "    \"23:onIfMatch = 2 -2\",\n",
    "    \"23:onIfMatch = 3 -3\",\n",
    "    \"23:onIfMatch = 4 -4\",\n",
    "    \"23:onIfMatch = 5 -5\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### defining the detector\n",
    "detector = pm.utils.SphericalTracker(\n",
    "    ### with this option detector measures total energy\n",
    "    ### of the particles traversing each pixel.\n",
    "    is_binary=False,\n",
    "    \n",
    "    ### detector covers [0, 5] pseudo-rapidity range\n",
    "    max_pseudorapidity=5.0,\n",
    "    pseudorapidity_steps=32, phi_steps=32,\n",
    "    ### 1 layer with radius 10 mm.\n",
    "    n_layers=1, R_min=10.0, R_max=10.0,\n",
    ")\n",
    "    \n",
    "mill = pm.ParametrizedPythiaMill(\n",
    "    detector, options,\n",
    "    ### please, don't use number of workers higher than 4.\n",
    "    batch_size=8, n_workers=4,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(mill, detector_configurations, show_progress=False):\n",
    "    \"\"\"\n",
    "    Utilitary function to obtain data for a particular set of configurations.\n",
    "    \n",
    "    :param mill: instance of Pythia Mill to sample from.\n",
    "    : param detector configuration: - list of configurations.\n",
    "        each configuration should be an array of detector parameters.\n",
    "    : param show_progress: if True shows progress via `tqdm` package. \n",
    "    \n",
    "    :return:\n",
    "        - parameters: array of shape `<number of samples> x <parameters dim>`, parameters for each sample;\n",
    "        - samples: array of shape `<number of samples> x 1 x 32 x 32`, sampled events.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ### sending requests to the queue\n",
    "        for args in detector_configurations:\n",
    "            mill.request(*args)\n",
    "\n",
    "        ### retrieving results\n",
    "        data = [\n",
    "            mill.retrieve()\n",
    "            for _ in (\n",
    "                (lambda x: tqdm_notebook(x, postfix='data gen', leave=False))\n",
    "                if show_progress else\n",
    "                (lambda x: x)\n",
    "            )(range(len(detector_configurations)))\n",
    "        ]\n",
    "\n",
    "        samples = np.vstack([ samples for params, samples in data ])\n",
    "        params = np.vstack([ np.array([params] * samples.shape[0], dtype='float32') for params, samples in data ])\n",
    "\n",
    "        return params, samples.reshape(-1, 32, 32, 1)\n",
    "    finally:\n",
    "        while mill.n_requests > 0:\n",
    "            mill.retrieve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating training samples with ground truth parameters.\n",
    "### For a real-world problem these arrays would correspond to real data.\n",
    "_, X_true_train = get_data(mill, detector_configurations=[(TRUE_OFFSET, )] * 2 ** 12, show_progress=True)\n",
    "_, X_true_val = get_data(mill, detector_configurations=[(TRUE_OFFSET, )] * 2 ** 12, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_true_train.shape)\n",
    "print(X_true_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "plt.subplots(nrows=n, ncols=n, figsize=(3 * n, 3 * n))\n",
    "\n",
    "max_energy = np.max(X_true_train[:n * n])\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        k = i * n + j\n",
    "        plt.subplot(n, n, k + 1)\n",
    "        plt.imshow(X_true_train[k, :, :, 0], vmin=0, vmax=max_energy)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(np.sum(X_true_train, axis=(0, 3)), vmin=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, GlobalMaxPool2D\n",
    "from keras.activations import softplus, sigmoid, relu\n",
    "\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building conv net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 32, 1))\n",
    "\n",
    "activation = lambda x: relu(x, 0.05)\n",
    "\n",
    "net = Conv2D(8, kernel_size=(3, 3), padding='same', activation=activation)(inputs)\n",
    "net = MaxPool2D(pool_size=(2, 2))(net)\n",
    "\n",
    "net = Conv2D(12, kernel_size=(3, 3), padding='same', activation=activation)(net)\n",
    "net = MaxPool2D(pool_size=(2, 2))(net)\n",
    "# net = GlobalMaxPool2D()(net)\n",
    "\n",
    "\n",
    "net = Conv2D(16, kernel_size=(3, 3), padding='same', activation=activation)(net)\n",
    "net = MaxPool2D(pool_size=(2, 2))(net)\n",
    "\n",
    "net = Conv2D(24, kernel_size=(3, 3), padding='same', activation=activation)(net)\n",
    "net = MaxPool2D(pool_size=(2, 2))(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "predictions = Dense(1, activation=sigmoid)(net)\n",
    "\n",
    "discriminator = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from IPython.display import SVG\n",
    "\n",
    "SVG(model_to_dot(discriminator, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Adversarial Variational Optimization, instead of searching for a single value of detector parameters, a parametrized distribution is introduced (with parameters $\\psi$):\n",
    "\n",
    "$$\\mathcal{L}(\\psi) = \\mathrm{JS}(X_\\psi, X_\\mathrm{data})$$\n",
    "where:\n",
    "- $X_\\psi \\sim \\mathrm{detector}(\\theta), \\theta \\sim P_\\psi$;\n",
    "- $X_\\mathrm{data} \\sim \\mathrm{reality}$.\n",
    "\n",
    "Note that $\\mathcal{L}(\\psi)$ is a vaiational bound on adversarial loss:\n",
    "\n",
    "$$\\mathcal{L}(\\psi) \\geq \\min_\\theta \\mathcal{L}_\\mathrm{adv}(\\theta) = \\mathrm{JS}(X_\\theta, X_\\mathrm{data})$$\n",
    "\n",
    "In this example, detector parameters consist of a signle `offset` parameter. For simplicity normal distibution is used:\n",
    "\n",
    "$$\\mathrm{offset} \\sim \\mathcal{N}(\\mu, \\sigma)$$\n",
    "\n",
    "\n",
    "In order to avoid introducing constraints $\\sigma \\geq 0$, an auxiliary *free variable* $\\sigma'$ is introduced (denoted as `detector_params_sigma_raw` in the code):\n",
    "$$\\sigma = \\log(1 + \\exp(\\sigma'))$$\n",
    "\n",
    "Note that if there exists configuration of detector perfectly matching real data, then minimum of variational bound is achieved when the `offset` distribution collapses into delta function with the center at minumum of adversarial loss.\n",
    "Otherwise, a mixture of detector configuations might be a solution (unlike convetional variational optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype='float32', shape=(None, 32, 32, 1))\n",
    "\n",
    "proba = discriminator(X)[:, 0]\n",
    "\n",
    "detector_params = tf.placeholder(dtype='float32', shape=(None, 1))\n",
    "\n",
    "detector_params_mean = tf.Variable(\n",
    "    initial_value=np.array([0.0], dtype='float32'),\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "detector_params_sigma_raw = tf.Variable(\n",
    "    initial_value=np.array([2.0], dtype='float32'),\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "detector_params_sigma = tf.nn.softplus(detector_params_sigma_raw)\n",
    "\n",
    "neg_log_prob = tf.reduce_sum(\n",
    "    tf.log(detector_params_sigma)\n",
    ") + tf.reduce_sum(\n",
    "    0.5 * (detector_params - detector_params_mean[None, :]) ** 2 / detector_params_sigma[None, :] ** 2\n",
    "    , axis=1\n",
    ")\n",
    "\n",
    "detector_params_loss = tf.reduce_mean(neg_log_prob * proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_distribution_params = lambda : tf_session.run([detector_params_mean, detector_params_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = tf.placeholder(dtype='int64', shape=())\n",
    "params_sample = tf.random_normal(\n",
    "    mean=detector_params_mean,\n",
    "    stddev=detector_params_sigma,\n",
    "    shape=(n, 1),\n",
    "    dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_opt = tf.train.AdamOptimizer(learning_rate=0.02).minimize(\n",
    "    detector_params_loss, var_list=[detector_params_mean, detector_params_sigma_raw]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(n_samples=2 ** 16, n_epoches=16, plot=False):\n",
    "    sample_of_detector_params = tf_session.run(params_sample, { n : n_samples // 8 })\n",
    "    \n",
    "    _, X_gen_train = get_data(\n",
    "        mill,\n",
    "        detector_configurations=sample_of_detector_params,\n",
    "        show_progress=True\n",
    "    )\n",
    "    \n",
    "    X_train = np.vstack([ X_gen_train, X_true_train ])\n",
    "    y_train = np.hstack([ np.zeros(X_gen_train.shape[0]), np.ones(X_true_train.shape[0]) ]).astype('float32')\n",
    "    \n",
    "    history = discriminator.fit(x=X_train, y=y_train, batch_size=32, epochs=n_epoches, verbose=0)\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(history.history['loss'], label='train loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    sample_of_detector_params = tf_session.run(params_sample, { n : 2 ** 8 })\n",
    "    params_train, X_gen_train = get_data(mill, detector_configurations=sample_of_detector_params)\n",
    "    \n",
    "    tf_session.run(\n",
    "        distribution_opt,\n",
    "        feed_dict={\n",
    "            X : X_gen_train,\n",
    "            detector_params : params_train\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVO makes small changes in parameter distribution. When starting with the optimal discriminator from the previous iterations, adjusting discriminator to these changes should require relatively few optimization steps.\n",
    "\n",
    "However, the initial discriminator state (which is just random weights), most probably, does not correspond to any optimal discriminator. Therefore, we pretrain discriminator in order to ensure that only a few epoches needed on each iteration to achieve an optimal discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_discriminator(n_samples=2**16, n_epoches=4, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "n_iterations = 256\n",
    "\n",
    "generator_mean_history = np.ndarray(shape=(n_iterations, ))\n",
    "generator_sigma_history = np.ndarray(shape=(n_iterations, ))\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    train_discriminator(n_samples=2**12, n_epoches=1)\n",
    "    train_generator()\n",
    "    \n",
    "    m, s = get_distribution_params()\n",
    "    generator_mean_history[i] = np.float32(m[0])\n",
    "    generator_sigma_history[i] = np.float32(s[0])\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    plt.figure(figsize=(18, 9))\n",
    "    plt.plot(generator_mean_history[:i + 1], color='blue', label='mean ($\\\\mu$)')\n",
    "\n",
    "    plt.fill_between(\n",
    "        np.arange(i + 1),\n",
    "        generator_mean_history[:i + 1] - generator_sigma_history[:i + 1],\n",
    "        generator_mean_history[:i + 1] + generator_sigma_history[:i + 1],\n",
    "        color='blue',\n",
    "        label='sigma ($\\\\sigma$)',\n",
    "        alpha=0.2\n",
    "    )\n",
    "    \n",
    "    plt.plot([0, n_iterations - 1], [TRUE_OFFSET, TRUE_OFFSET], '--', color='black', alpha=0.5, label='ground truth')\n",
    "    plt.ylim([-2, 4])\n",
    "    plt.legend(loc='upper left', fontsize=18)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.xlabel('AVO step', fontsize=16)\n",
    "    plt.ylabel('detector offset', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
